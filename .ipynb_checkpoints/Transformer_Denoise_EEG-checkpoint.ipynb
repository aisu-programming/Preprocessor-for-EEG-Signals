{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8222e63f-7e4a-4607-a88a-da5752a2f4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Libraries #####\n",
    "import dotenv\n",
    "dotenv.load_dotenv(\".env\")\n",
    "import os\n",
    "import time\n",
    "import utils\n",
    "import shutil\n",
    "import argparse\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(0)\n",
    "tf.keras.utils.set_random_seed(0)\n",
    "import models_tensorflow.EEGModels\n",
    "from typing import Literal\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras import utils as tf_utils\n",
    "backend.set_image_data_format(\"channels_last\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import utils\n",
    "from utils import Metric, plot_confusion_matrix, plot_history\n",
    "from libs.dataset import BcicIv2aDataset, InnerSpeechDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a459cc27-5147-42a3-947f-e91a582d3e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"DATASET_DIR\"] = 'datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eca5120-a92a-44e7-927d-8604417ec586",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading BCIC IV 2a dataset - A09E: 100%|████████| 18/18 [00:22<00:00,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset = BcicIv2aDataset()  # l_freq=4\n",
    "inputs, truths = dataset.all_data_and_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22090b3b-af30-44d5-87a7-eea2479d5c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5184, 22, 257)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "381b819f-9722-42cf-ac10-7151a9eb7e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5184, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1feb17e-e3e3-474d-9d90-0df4b5d68c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False,  True])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94054874-d99f-441b-b04b-e5e6aaa380ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5011255-66b8-4911-9e2b-76257a3e99a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c conda-forge tensorflow-addons -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e074e47-2914-4377-9cfe-40b730b262b9",
   "metadata": {},
   "source": [
    "## Transformer Build and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1527d0-bd6f-403b-9cc9-cf8a16ba071b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4d681cd0-5fc5-4c62-97d7-2aa08e7be9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import MultiHeadAttention, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# Time2Vec layer: This layer provides a method to encode both linear and periodic components of time into the model inputs.\n",
    "class Time2Vec(keras.layers.Layer):\n",
    "    def __init__(self, kernel_size=1):\n",
    "        super(Time2Vec, self).__init__(trainable=True, name='Time2VecLayer')\n",
    "        self.k = kernel_size\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # Initialize weights and biases with proper shapes\n",
    "        self.wb = self.add_weight(name='wb', shape=(1, input_shape[1], 1), initializer='uniform', trainable=True)\n",
    "        self.bb = self.add_weight(name='bb', shape=(1, input_shape[1], 1), initializer='uniform', trainable=True)\n",
    "        self.wa = self.add_weight(name='wa', shape=(1, input_shape[1], self.k), initializer='uniform', trainable=True)\n",
    "        self.ba = self.add_weight(name='ba', shape=(1, input_shape[1], self.k), initializer='uniform', trainable=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # Apply linear transformation\n",
    "        bias = self.wb * inputs + self.bb  # Broadcasted across the last dimension\n",
    "        \n",
    "        # Apply periodic transformation\n",
    "        dp = tf.reduce_sum(inputs * self.wa, axis=-1, keepdims=True) + self.ba  # Weighted sum across the time dimension\n",
    "        wgts = tf.math.sin(dp)  # Apply the sinusoidal function\n",
    "        \n",
    "        # Concatenate bias and weights along the last dimension\n",
    "        return tf.concat([bias, wgts], axis=-1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        # Adjust output shape considering the concatenation of bias and periodic components\n",
    "        return (input_shape[0], input_shape[1], 1 + self.k)\n",
    "\n",
    "\n",
    "\n",
    "# AttentionBlock: This is a custom layer that incorporates multi-head self-attention mechanism, allowing the model to focus on different parts of the input sequence.\n",
    "# class AttentionBlock(keras.Model):\n",
    "#     def __init__(self, num_heads=2, head_size=128, ff_dim=256, dropout=0.1, feature_dim=515, **kwargs):\n",
    "#         super(AttentionBlock, self).__init__(**kwargs)\n",
    "#         self.num_heads = num_heads\n",
    "#         self.head_size = head_size\n",
    "#         self.dropout = dropout\n",
    "#         self.attention = MultiHeadAttention(num_heads=num_heads, key_dim=head_size, dropout=dropout)\n",
    "#         self.att_norm = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "#         self.ff_norm = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "#         self.ff_conv1 = Dense(ff_dim, activation='relu')\n",
    "#         self.ff_conv2 = Dense(feature_dim)  # Ensure this matches the input feature dimension\n",
    "\n",
    "#     def call(self, inputs, training=False):\n",
    "#         attn_output = self.attention(query=inputs, key=inputs, value=inputs)\n",
    "#         attn_output = Dropout(self.dropout)(attn_output, training=training)\n",
    "#         out1 = self.att_norm(inputs + attn_output)\n",
    "\n",
    "#         ffn_output = self.ff_conv1(out1)\n",
    "#         ffn_output = self.ff_conv2(ffn_output)\n",
    "#         ffn_output = Dropout(self.dropout)(ffn_output, training=training)\n",
    "#         return self.ff_norm(out1 + ffn_output)\n",
    "\n",
    "class AttentionBlock(keras.Model):\n",
    "    def __init__(self, num_heads=2, head_size=128, ff_dim=256, dropout=0.1, feature_dim=515, **kwargs):\n",
    "        super(AttentionBlock, self).__init__(**kwargs)\n",
    "        self.num_heads = num_heads\n",
    "        self.head_size = head_size\n",
    "        self.dropout_rate = dropout\n",
    "        self.feature_dim = feature_dim\n",
    "        \n",
    "        self.attention = MultiHeadAttention(num_heads=num_heads, key_dim=head_size, dropout=dropout)\n",
    "        self.att_norm = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.ff_conv1 = Dense(ff_dim, activation='relu')\n",
    "        self.ff_conv2 = Dense(feature_dim)  # Matches the input feature dimension\n",
    "        self.ff_norm = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout_layer = Dropout(dropout)  # Properly define dropout as a layer attribute\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.attention(query=inputs, key=inputs, value=inputs)\n",
    "        attn_output = self.dropout_layer(attn_output, training=training)  # Use the layer attribute for dropout\n",
    "        out1 = self.att_norm(inputs + attn_output)\n",
    "        \n",
    "        ffn_output = self.ff_conv1(out1)\n",
    "        ffn_output = self.ff_conv2(ffn_output)\n",
    "        ffn_output = self.dropout_layer(ffn_output, training=training)  # Reuse the same dropout layer\n",
    "        return self.ff_norm(out1 + ffn_output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TransformerModel: This class defines the overall model architecture combining Time2Vec and multiple AttentionBlocks.\n",
    "class TransformerModel(Model):\n",
    "    def __init__(self, time2vec_dim=1, num_heads=2, head_size=128, ff_dim=256, num_layers=3, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.time2vec = Time2Vec(kernel_size=time2vec_dim)\n",
    "        self.attention_blocks = [AttentionBlock(num_heads=num_heads, head_size=head_size, ff_dim=ff_dim, dropout=dropout) for _ in range(num_layers)]\n",
    "        self.final_layer = layers.Dense(units=257, activation='linear')  # Assuming output dimension equals the time series length\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.time2vec(inputs)\n",
    "        x = layers.Concatenate(axis=-1)([inputs, x])\n",
    "        for block in self.attention_blocks:\n",
    "            x = block(x)\n",
    "        x = self.final_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8bc7757c-ba77-497d-8403-c8675cb70bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5184, 22, 257)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "932fe671-a16a-413c-a820-265aa58282ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example function to load dataset (this should be replaced with actual data loading)\n",
    "def load_dataset():\n",
    "    x =  inputs #  np.random.rand(100, 22, 257)  # Simulated input data\n",
    "    y =  inputs # np.random.rand(100, 22, 257)  # Simulated ground truth data\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e12c962-74f9-45d0-962e-9936e40c7b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, truths = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eee601f8-2d28-4a5a-a393-31dc81712d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# truths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb7400e3-ac7a-44dd-b926-9250881bb95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data to range [0, 1] for consistency and to aid learning.\n",
    "inputs = (inputs - np.min(inputs)) / (np.max(inputs) - np.min(inputs))\n",
    "truths = (truths - np.min(truths)) / (np.max(truths) - np.min(truths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1ce5b0d3-c030-4d59-aebb-d83b3bd77111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets to evaluate model performance.\n",
    "x_train, x_test, y_train, y_test = train_test_split(inputs, truths, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d467d66-e765-43ee-9160-8afe1a0c164e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4147, 22, 257)\n",
      "(4147, 22, 257)\n",
      "(1037, 22, 257)\n",
      "(1037, 22, 257)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "33f6fa89-854c-440f-a33b-c2ab8e861e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure and compile the model\n",
    "model = TransformerModel(time2vec_dim=1, num_heads=2, head_size=128, ff_dim=256, num_layers=3, dropout=0.1)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')  # Use Adam optimizer and MSE loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0fc420fe-ddfe-46cb-ad77-46a1ce081421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d2a5d5c4-ffe1-4213-bbbe-5ef4a6c648c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Learning Rate Scheduler to adjust the learning rate dynamically during training for better performance.\n",
    "def lr_scheduler(epoch, lr):\n",
    "    warmup_epochs = 15\n",
    "    decay_epochs = 100\n",
    "    initial_lr = 1e-6\n",
    "    base_lr = 1e-3\n",
    "    min_lr = 5e-5\n",
    "    if epoch <= warmup_epochs:\n",
    "        pct = epoch / warmup_epochs\n",
    "        return ((base_lr - initial_lr) * pct) + initial_lr\n",
    "    if epoch > warmup_epochs and epoch < warmup_epochs + decay_epochs:\n",
    "        pct = 1 - ((epoch - warmup_epochs) / decay_epochs)\n",
    "        return ((base_lr - min_lr) * pct) + min_lr\n",
    "    return min_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "932e2092-9ce4-49f4-bc82-bf912cbf7d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 97ms/step - loss: 0.1317 - val_loss: 0.0024\n",
      "Epoch 2/5\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 105ms/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 3/5\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 104ms/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 4/5\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 95ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 5/5\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 99ms/step - loss: 0.0025 - val_loss: 0.0027\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2e9b0d400>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_list = [LearningRateScheduler(lr_scheduler, verbose=1)]\n",
    "\n",
    "# Train the model with the specified configurations.\n",
    "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test), batch_size=32) # callbacks=callback_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "19486b1a-4923-4324-8d5d-46b719d5e911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 33ms/step\n",
      "Shape of the predicted outputs: (4147, 22, 257)\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'model' is the trained Transformer model and 'x_test' is the test dataset\n",
    "\n",
    "# Predict the outputs for the test set\n",
    "predicted_outputs = model.predict(x_train)\n",
    "\n",
    "# You can now use 'predicted_outputs' for further analysis, visualization, or post-processing\n",
    "# For example, printing the shape of the outputs and some sample data\n",
    "print(\"Shape of the predicted outputs:\", predicted_outputs.shape)\n",
    "# print(\"Sample predictions:\", predicted_outputs[:5])\n",
    "\n",
    "# If you need to compare these predictions with the actual labels\n",
    "# Assuming 'y_test' contains the true values for the test set\n",
    "# print(\"Actual true outputs:\", y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4706829a-8bca-44d4-bbb1-bd2fe3c7ec8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. None expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# calculate the performance metrics, 'Mean Squared Error'\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[0;32m----> 4\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_train, predicted_outputs)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Squared Error on Test Set:\u001b[39m\u001b[38;5;124m\"\u001b[39m, mse)\n",
      "File \u001b[0;32m~/miniforge3/envs/eeg/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/eeg/lib/python3.12/site-packages/sklearn/metrics/_regression.py:497\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[1;32m    493\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[1;32m    494\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[1;32m    495\u001b[0m         )\n\u001b[0;32m--> 497\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m _check_reg_targets(\n\u001b[1;32m    498\u001b[0m     y_true, y_pred, multioutput\n\u001b[1;32m    499\u001b[0m )\n\u001b[1;32m    500\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    501\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/miniforge3/envs/eeg/lib/python3.12/site-packages/sklearn/metrics/_regression.py:103\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m--> 103\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    104\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/eeg/lib/python3.12/site-packages/sklearn/utils/validation.py:1043\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1039\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1041\u001b[0m     )\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m-> 1043\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1044\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1045\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m   1046\u001b[0m     )\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m   1049\u001b[0m     _assert_all_finite(\n\u001b[1;32m   1050\u001b[0m         array,\n\u001b[1;32m   1051\u001b[0m         input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m   1052\u001b[0m         estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m   1053\u001b[0m         allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1054\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. None expected <= 2."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# calculate the performance metrics, 'Mean Squared Error'\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_train, predicted_outputs)\n",
    "print(\"Mean Squared Error on Test Set:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "30b174d0-098c-407c-83e0-4b07b589c1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error per feature, averaged over time steps: 0.002535971542483811\n"
     ]
    }
   ],
   "source": [
    "# Calculate MSE for each feature and average over all time steps\n",
    "mse_per_feature = np.mean([mean_squared_error(y_train[:, i, :], predicted_outputs[:, i, :]) for i in range(y_train.shape[1])])\n",
    "print(\"Mean Squared Error per feature, averaged over time steps:\", mse_per_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1f595325-9238-4bdb-8d4d-7577eb5973fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Channel 1: 0.002892112152690684\n",
      "MSE for Channel 2: 0.002365045193164491\n",
      "MSE for Channel 3: 0.00265804448155546\n",
      "MSE for Channel 4: 0.002930883197617\n",
      "MSE for Channel 5: 0.0027586019778895925\n",
      "MSE for Channel 6: 0.0025873186748943417\n",
      "MSE for Channel 7: 0.001653848754940294\n",
      "MSE for Channel 8: 0.002205535325460935\n",
      "MSE for Channel 9: 0.0024582938756672764\n",
      "MSE for Channel 10: 0.002783532164773731\n",
      "MSE for Channel 11: 0.0026102892130813664\n",
      "MSE for Channel 12: 0.002585270767988162\n",
      "MSE for Channel 13: 0.002167161265563858\n",
      "MSE for Channel 14: 0.002296732904307401\n",
      "MSE for Channel 15: 0.0024126604748039232\n",
      "MSE for Channel 16: 0.002615999525986123\n",
      "MSE for Channel 17: 0.0025995530125059595\n",
      "MSE for Channel 18: 0.0027031042723586005\n",
      "MSE for Channel 19: 0.0024519940378041174\n",
      "MSE for Channel 20: 0.002726288487523727\n",
      "MSE for Channel 21: 0.0026341128879922068\n",
      "MSE for Channel 22: 0.0026949912860745858\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Initialize a list or numpy array to store the MSE values for each channel\n",
    "mse_per_channel = np.zeros((y_train.shape[1],))  # y_train.shape[1] should be 22 if there are 22 channels\n",
    "\n",
    "# Loop through each channel and calculate MSE\n",
    "for channel_index in range(y_train.shape[1]):\n",
    "    # Extract the channel data for both true and predicted values\n",
    "    true_channel_data = y_train[:, channel_index, :]\n",
    "    predicted_channel_data = predicted_outputs[:, channel_index, :]\n",
    "\n",
    "    # Compute the MSE for this channel\n",
    "    mse_per_channel[channel_index] = mean_squared_error(true_channel_data, predicted_channel_data)\n",
    "\n",
    "    # Optionally, print the MSE for each channel\n",
    "    print(f\"MSE for Channel {channel_index + 1}: {mse_per_channel[channel_index]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccc67a6-0d8e-49a3-ae76-c0eb36ada468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
